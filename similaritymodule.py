import os
import cv2
import numpy as np
import tensorflow as tf
from tensorflow.keras.models import load_model, Model
from skimage.metrics import structural_similarity as ssim

# ============================================
# 1) ë”¥ëŸ¬ë‹ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
# ============================================

BASE_DIR = os.path.dirname(__file__)
MODEL_PATH = os.path.join(BASE_DIR, "model_7.h5")

_EMBEDDER = None
_HWC = None

def _load_embedder():
    global _EMBEDDER, _HWC
    if _EMBEDDER is not None:
        return

    # ëª¨ë¸ íŒŒì¼ì´ ì—†ìœ¼ë©´ ë”ë¯¸ ëª¨ë“œë¡œ ë™ì‘ (ì—ëŸ¬ ë°©ì§€)
    if not os.path.exists(MODEL_PATH):
        print(f"[SIMILARITY] Model not found at {MODEL_PATH}")
        return

    try:
        base = load_model(MODEL_PATH, compile=False)
        in_shape = tuple(base.input_shape[1:])
        _HWC = in_shape

        inp = tf.keras.Input(shape=in_shape)
        x = inp
        for layer in base.layers[:-1]:
            x = layer(x)
        _EMBEDDER = Model(inp, x, name="embedder")
        print(f"[SIMILARITY] Embedder loaded. Input={in_shape}")
    except Exception as e:
        print(f"[SIMILARITY] Failed to load model: {e}")
        _EMBEDDER = None
        _HWC = None

# ============================================
# 2) ì´ë¯¸ì§€ ì „ì²˜ë¦¬ ë° ì¸¡ì • í•¨ìˆ˜ë“¤
# ============================================

def _preprocess_dl(img, size):
    """ë”¥ëŸ¬ë‹ ëª¨ë¸ìš© ì „ì²˜ë¦¬"""
    # Grayscale -> RGB (ëª¨ë¸ì´ 3ì±„ë„ì¼ ê²½ìš°)
    if img.ndim == 2:
        img = cv2.cvtColor(img, cv2.COLOR_GRAY2BGR)
    elif img.shape[2] == 4:
        img = cv2.cvtColor(img, cv2.COLOR_BGRA2BGR)

    img_resized = cv2.resize(img, (size[1], size[0]))
    x = (img_resized.astype("float32") / 255.0)[None, ...]
    return x

def _get_embedding(img):
    """ë”¥ëŸ¬ë‹ ì„ë² ë”© ì¶”ì¶œ"""
    _load_embedder()
    if _EMBEDDER is None or _HWC is None:
        # ëª¨ë¸ì´ ì—†ìœ¼ë©´ ê·¸ëƒ¥ 128-dim zero ë²¡í„° ë°˜í™˜ (fallback)
        return np.zeros(128, dtype="float32")

    H, W, C = _HWC
    x = _preprocess_dl(img, size=(H, W))
    e = _EMBEDDER.predict(x, verbose=0)[0]
    return e / (np.linalg.norm(e) + 1e-9)

def _calc_ssim(img1, img2):
    """3. êµ¬ì¡°ì  ì •í™•ë„ (SSIM)"""
    # í‘ë°± ë³€í™˜ ë° í¬ê¸° í†µì¼
    i1 = cv2.resize(img1, (128, 128))
    i2 = cv2.resize(img2, (128, 128))
    if i1.ndim == 3:
        i1 = cv2.cvtColor(i1, cv2.COLOR_BGR2GRAY)
    if i2.ndim == 3:
        i2 = cv2.cvtColor(i2, cv2.COLOR_BGR2GRAY)

    score, _ = ssim(i1, i2, full=True)
    return float(max(0.0, min(1.0, score)))

def _calc_hist_corr(img1, img2):
    """4. íš ë‘ê»˜/ë†ë„ (íˆìŠ¤í† ê·¸ë¨ ìƒê´€ê´€ê³„)"""
    # í‘ë°± ë³€í™˜
    if img1.ndim == 3:
        img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
    if img2.ndim == 3:
        img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

    # íˆìŠ¤í† ê·¸ë¨ ê³„ì‚°
    hist1 = cv2.calcHist([img1], [0], None, [256], [0, 256])
    hist2 = cv2.calcHist([img2], [0], None, [256], [0, 256])

    # ì •ê·œí™”
    cv2.normalize(hist1, hist1, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)
    cv2.normalize(hist2, hist2, alpha=0, beta=1, norm_type=cv2.NORM_MINMAX)

    # ìƒê´€ê´€ê³„ ë¹„êµ (1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ë¶„í¬ê°€ ë¹„ìŠ·í•¨)
    score = cv2.compareHist(hist1, hist2, cv2.HISTCMP_CORREL)
    return float(max(0.0, min(1.0, score)))

def _calc_shape_sim(img1, img2):
    """5. ê¸€ì ì™¸í˜• (Hu Moments)"""
    # ì´ì§„í™” (Thresholding)
    if img1.ndim == 3:
        img1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
    if img2.ndim == 3:
        img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

    _, th1 = cv2.threshold(img1, 127, 255, cv2.THRESH_BINARY_INV)
    _, th2 = cv2.threshold(img2, 127, 255, cv2.THRESH_BINARY_INV)

    # Hu Moments ê¸°ë°˜ shape distance (ë‚®ì„ìˆ˜ë¡ ë¹„ìŠ·)
    d = cv2.matchShapes(th1, th2, cv2.CONTOURS_MATCH_I1, 0)

    # ì ìˆ˜í™”: ê±°ë¦¬ê°€ 0ì´ë©´ 1ì , ë©€ì–´ì§ˆìˆ˜ë¡ 0ìœ¼ë¡œ ìˆ˜ë ´
    score = 1.0 / (1.0 + d)
    return float(max(0.0, min(1.0, score)))

# ============================================
# 3) ë©”ì¸ í•¨ìˆ˜
# ============================================

TARGET_TEXT = "ë™í•´ë¬¼ê³¼ë°±ë‘ì‚°ì´ë§ˆë¥´ê³ ë‹³ë„ë¡"

def compute_similarity(job_id: str, out_dir: str, handwriting_subdir: str = "handwriting") -> dict:
    """
    job_id: "1764..." ê°™ì€ ë¬¸ìì—´
    out_dir: result{jobId} ë””ë ‰í† ë¦¬ ê²½ë¡œ (app.pyì—ì„œ ë„˜ê²¨ì¤Œ)
    handwriting_subdir: "handwriting" ë˜ëŠ” "retry"
    """
    _load_embedder()

    job_root = out_dir
    hand_dir = os.path.join(job_root, handwriting_subdir)
    gen_dir  = os.path.join(job_root, "generation")

    if not os.path.isdir(hand_dir) or not os.path.isdir(gen_dir):
        print(f"[SIMILARITY] missing dir: hand={hand_dir}, gen={gen_dir}")
        return {
            "AI í•„ì²´ ìœ ì‚¬ë„": 0.0,
            "íŠ¹ì§• ì¼ì¹˜ë„": 0.0,
            "êµ¬ì¡°ì  ì •í™•ë„": 0.0,
            "íš ë†ë„": 0.0,
            "ê¸€ì ì™¸í˜•": 0.0,
        }

    # ë§¤ì¹­ë˜ëŠ” íŒŒì¼ ìŒ ì°¾ê¸°
    pairs = []

    # (ì£¼ì˜) ì¤‘ê°„ ë°œí‘œìš©ìœ¼ë¡œ 1ê¸€ìë§Œ ìƒì„±í–ˆë‹¤ë©´, ìƒì„±ëœ íŒŒì¼ì´ ìˆëŠ” ê²ƒë§Œ ë¹„êµí•©ë‹ˆë‹¤.
    for idx, ch in enumerate(TARGET_TEXT, start=1):
        # ìƒì„±ë³¸ ì´ë¦„: jobId_generated_c{idx}.png
        gen_name = f"{job_id}_generated_c{idx}.png"
        g_path = os.path.join(gen_dir, gen_name)
        if not os.path.exists(g_path):
            continue

        # ì†ê¸€ì”¨ ìª½ì€ ë‹¤ì–‘í•œ ë„¤ì´ë° ê°€ëŠ¥ì„±(ìœ ë‹ˆì½”ë“œ, 0.png ë“±)ì„ ëª¨ë‘ ì¼€ì–´
        unicode_name = f"{ord(ch)}.png"
        numeric_name = f"{idx-1}.png"   # 0.png,1.png,... íŒ¨í„´

        candidates = [
            os.path.join(hand_dir, unicode_name),
            os.path.join(hand_dir, numeric_name),
        ]

        hand_path = None
        for cand in candidates:
            if os.path.exists(cand):
                hand_path = cand
                break

        if hand_path is None:
            print(f"[SIMILARITY] no handwriting file for char '{ch}' (idx={idx})")
            continue

        pairs.append((hand_path, g_path))

    print(f"[SIMILARITY] matched pairs = {len(pairs)}")

    if not pairs:
        print("[SIMILARITY] No pairs found.")
        return {
            "AI í•„ì²´ ìœ ì‚¬ë„": 0.0,
            "íŠ¹ì§• ì¼ì¹˜ë„": 0.0,
            "êµ¬ì¡°ì  ì •í™•ë„": 0.0,
            "íš ë†ë„": 0.0,
            "ê¸€ì ì™¸í˜•": 0.0,
        }

    # ì§€í‘œë³„ ì ìˆ˜ ë¦¬ìŠ¤íŠ¸
    scores_cos = []
    scores_l2 = []
    scores_ssim = []
    scores_hist = []
    scores_shape = []

    for h_path, g_path in pairs:
        # ì´ë¯¸ì§€ ë¡œë“œ
        img_h = cv2.imread(h_path, cv2.IMREAD_UNCHANGED) # ì›ë³¸
        img_g = cv2.imread(g_path, cv2.IMREAD_UNCHANGED) # ìƒì„±ë³¸
        if img_h is None or img_g is None:
            print(f"[SIMILARITY] failed to read: {h_path} or {g_path}")
            continue

        # ì•ŒíŒŒ ì±„ë„ ì œê±° / ì±„ë„ í†µì¼
        if img_h.ndim == 3 and img_h.shape[-1] == 4:
            img_h = cv2.cvtColor(img_h, cv2.COLOR_BGRA2BGR)
        if img_g.ndim == 3 and img_g.shape[-1] == 4:
            img_g = cv2.cvtColor(img_g, cv2.COLOR_BGRA2BGR)
        if img_h.ndim == 2:
            img_h = cv2.cvtColor(img_h, cv2.COLOR_GRAY2BGR)
        if img_g.ndim == 2:
            img_g = cv2.cvtColor(img_g, cv2.COLOR_GRAY2BGR)

        # 1. AI Cosine
        emb_h = _get_embedding(img_h)
        emb_g = _get_embedding(img_g)
        cos_sim = float(np.dot(emb_h, emb_g))
        scores_cos.append(cos_sim)

        # 2. AI L2 (ê±°ë¦¬ë¥¼ ì ìˆ˜í™”: 0ì— ê°€ê¹Œìš°ë©´ 1ì )
        l2_dist = float(np.linalg.norm(emb_h - emb_g))
        l2_score = 1.0 / (1.0 + l2_dist)
        scores_l2.append(l2_score)

        # 3. SSIM
        scores_ssim.append(_calc_ssim(img_h, img_g))

        # 4. Histogram
        scores_hist.append(_calc_hist_corr(img_h, img_g))

        # 5. Shape (Hu Moments)
        scores_shape.append(_calc_shape_sim(img_h, img_g))

    if not scores_cos:
        # ë¡œë”© ì‹¤íŒ¨ ë“±ìœ¼ë¡œ ì•„ë¬´ ê²ƒë„ ëª» ê³„ì‚°í•œ ê²½ìš°
        return {
            "AI í•„ì²´ ìœ ì‚¬ë„": 0.0,
            "íŠ¹ì§• ì¼ì¹˜ë„": 0.0,
            "êµ¬ì¡°ì  ì •í™•ë„": 0.0,
            "íš ë†ë„": 0.0,
            "ê¸€ì ì™¸í˜•": 0.0,
        }

    cos_mean   = float(np.mean(scores_cos))
    l2_mean    = float(np.mean(scores_l2))
    ssim_mean  = float(np.mean(scores_ssim))
    hist_mean  = float(np.mean(scores_hist))
    shape_mean = float(np.mean(scores_shape))

    # âœ… í”„ë¡ íŠ¸ê°€ ê¸°ëŒ€í•˜ëŠ” í‚¤ ê¸°ì¤€(ë ˆì´ë” ì°¨íŠ¸ìš©)
    metrics = {
        "cosine similarity":    round(cos_mean,  2),  # 1. cos sim
        "L2 Distance":          round(l2_mean,   2),  # 2. L2 score
        "SSIM(êµ¬ì¡°ì  ì •í™•ë„)":  round(ssim_mean, 2),  # 3. SSIM
        "íš ë‘ê»˜ ë†ë„":         round(hist_mean, 2),  # 4. histogram corr
        "ê¸€ì ì™¸í˜•":           round(shape_mean,2),  # 5. shape
    }

    # ğŸ”¹ í•œê¸€/ì˜›ë‚  í‚¤ë„ ê°™ì´ ë‚´ë ¤ì£¼ê³  ì‹¶ìœ¼ë©´ alias ë¡œ ì¶”ê°€
    metrics.update({
        "AI í•„ì²´ ìœ ì‚¬ë„": metrics["cosine similarity"],
        "íŠ¹ì§• ì¼ì¹˜ë„":   metrics["L2 Distance"],
        "êµ¬ì¡°ì  ì •í™•ë„": metrics["SSIM(êµ¬ì¡°ì  ì •í™•ë„)"],
        "íš ë†ë„":       metrics["íš ë‘ê»˜ ë†ë„"],
    })

    # (ì˜ˆì „ legacy í‚¤ ìœ ì§€í•˜ê³  ì‹¶ìœ¼ë©´ í•„ìš”ì— ë”°ë¼ ì¶”ê°€)
    # legacy = {
    #     "ê· í˜•":   metrics["SSIM(êµ¬ì¡°ì  ì •í™•ë„)"],
    #     "íšê°„ê²©": metrics["cosine similarity"],
    #     "ê¸°ìš¸ê¸°": metrics["ê¸€ì ì™¸í˜•"],
    #     "ìê°„":   metrics["L2 Distance"],
    #     "íšë‘ê»˜": metrics["íš ë‘ê»˜ ë†ë„"],
    # }
    # metrics.update(legacy)

    print(f"[SIMILARITY METRICS] {metrics}")
    return metrics
